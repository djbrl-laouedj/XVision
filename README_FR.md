# XVision

**XVision** est un projet de recherche multimodal vision‚Äìlangage ax√© sur la **t√©l√©d√©tection agricole**.  
Il combine des **images satellites multispectrales Sentinel-2** avec des **mod√®les de langage (LLM)** afin de g√©n√©rer automatiquement des **analyses agronomiques interpr√©tables** √† partir de donn√©es satellites.

Le projet suit des architectures multimodales modernes inspir√©es de mod√®les tels que LLaVA et BLIP-2, adapt√©es sp√©cifiquement aux donn√©es agricoles multispectrales.

---

## üåç Motivation du projet

L‚Äôimagerie satellite fournit des informations puissantes sur l‚Äô√©tat des cultures, mais l‚Äôinterpr√©tation des donn√©es multispectrales reste complexe et technique.

XVision vise √† combler ce foss√© en :
- Extrayant des repr√©sentations visuelles riches √† partir des images Sentinel-2
- Alignant ces repr√©sentations avec un mod√®le de langage
- G√©n√©rant des descriptions agronomiques lisibles par l‚Äôhumain (vigueur v√©g√©tative, humidit√©, biomasse, couverture sol/v√©g√©tation, etc.)

L‚Äôobjectif est de soutenir la **prise de d√©cision**, le **suivi** et l‚Äô**analyse** en agriculture gr√¢ce √† une interpr√©tation pilot√©e par l‚ÄôIA.

---

## Architecture globale

XVision est compos√© de trois composants principaux :

### 1. Encodeur visuel Sentinel-2 (CROMA-Large)
- Vision Transformer pr√©-entra√Æn√© sur des images multispectrales Sentinel-2
- Traite 12 bandes optiques
- Produit un **embedding de dimension 1024** par patch d‚Äôimage

### 2. Vision Adapter
- Un MLP l√©ger qui projette l‚Äôembedding visuel de dimension 1024
- Le convertit en une s√©quence de **tokens visuels**
- Aligne l‚Äôinformation visuelle avec l‚Äôespace d‚Äôembedding du LLM

### 3. Mod√®le de langage (Qwen2-1.5B + LoRA)
- LLM g√©n√©raliste adapt√© via un **fine-tuning LoRA**
- Apprend √† g√©n√©rer du texte agronomique conditionn√© par les tokens visuels
- Seule une petite fraction des param√®tres est entra√Æn√©e, permettant un fine-tuning efficace

---

## Pipeline de bout en bout

1. Image multispectrale Sentinel-2 (GeoTIFF)
2. Pr√©traitement et normalisation des bandes
3. Extraction des embeddings visuels avec CROMA
4. Projection via le Vision Adapter
5. Injection des tokens visuels dans le LLM
6. G√©n√©ration de texte (analyse agricole)

---

## Structure du d√©p√¥t

```XVision/

‚îú‚îÄ‚îÄ XVision-ViT.ipynb # G√©n√©ration des embeddings Sentinel-2 (CROMA)

‚îú‚îÄ‚îÄ XVision-Captions-Generator.ipynb # G√©n√©ration des captions agronomiques

‚îú‚îÄ‚îÄ XVision-LoRA.ipynb # Fine-tuning multimodal LoRA

‚îú‚îÄ‚îÄ XVision-inference.ipynb # Inf√©rence multimodale sur de nouvelles images

‚îú‚îÄ‚îÄ requirements.txt # D√©pendances Python

‚îú‚îÄ‚îÄ README.md # Documentation anglaise

‚îú‚îÄ‚îÄ README_FR.md # Documentation fran√ßaise

‚îî‚îÄ‚îÄ .gitignore
```

---

## Donn√©es & Captions

- Les embeddings visuels sont extraits √† partir de patches Sentinel-2 via CROMA-Large
- Les captions agronomiques sont g√©n√©r√©es automatiquement √† partir d‚Äôindices spectraux (NDVI, NDWI, SAVI, EVI, etc.)
- Les captions sont diversifi√©es, structur√©es et scientifiquement coh√©rentes afin d‚Äô√©viter le sur-apprentissage lors de l‚Äôentra√Ænement

---

## Strat√©gie d‚Äôentra√Ænement

- L‚Äôalignement multimodal est appris via un fine-tuning LoRA
- Le LLM de base reste gel√©
- Seuls le Vision Adapter et les couches LoRA sont entra√Æn√©s
- Cela permet :
  - Une r√©duction des co√ªts de calcul
  - Un entra√Ænement stable
  - Une meilleure g√©n√©ralisation

---

## Cas d‚Äôusage

- Suivi de parcelles agricoles
- Analyse de l‚Äô√©tat des cultures
- Syst√®mes d‚Äôaide √† la d√©cision
- G√©n√©ration augment√©e par r√©cup√©ration g√©ospatiale (RAG)
- Recherche sur l‚Äôapprentissage multimodal appliqu√© √† la t√©l√©d√©tection

---

## √âtat du projet

- Pipeline multimodal de bout en bout op√©rationnel
- Fine-tuning LoRA valid√©
- Inf√©rence fonctionnelle sur des images satellites non vues
- Am√©liorations en cours sur la diversit√© des captions et la qualit√© du dataset
- Extension pr√©vue vers l‚Äôanalyse multi-temporelle et d‚Äôautres types de cultures

---

## Licence

Ce projet est destin√© √† des usages de recherche et d‚Äôenseignement.
Veuillez vous r√©f√©rer aux licences des mod√®les et jeux de donn√©es sous-jacents (CROMA, Sentinel-2, Qwen).

---

## Socle technique

- Sentinel-2 / Programme Copernicus (ESA)
- TorchGeo & CROMA
- √âcosyst√®me Hugging Face
- Mod√®le Qwen
- LoRA & MLP

---

## üöÄ Lancer le projet

**1Ô∏è. Cloner le d√©p√¥t**
```
https://github.com/djbrl-laouedj/XVision.git
```
```
cd XVision
```

**2Ô∏è. Cr√©er et activer un environnement virtuel (recommand√©)**
```
python -m venv venv
```
```
source venv/bin/activate        # Linux / macOS
```
```
venv\Scripts\activate           # Windows
```

**3Ô∏è. Installer les d√©pendances**
```
pip install --upgrade pip
```
```
pip install -r requirements.txt
```
‚ö†Ô∏è Un GPU compatible CUDA est fortement recommand√© pour l‚Äôentra√Ænement (fine-tuning LoRA).

### Ex√©cution du pipeline (√©tape par √©tape)

**√âtape 1 ‚Äî G√©n√©rer les embeddings Sentinel-2 (sentinel_embeddings_1024.npy) - Encodeur visuel**

Lancer :
```
XVision-ViT.ipynb
```

**√âtape 2 ‚Äî G√©n√©rer les captions agronomiques (sentinel_indices.jsonl) - optionnel mais recommand√©**

Lancer :
```
XVision-Captions-Generator.ipynb
```

**√âtape 3 ‚Äî Fine-tuning multimodal LoRA**

Lancer :
```
XVision-LoRA.ipynb
```
Sorties :

- vision_adapter.pt

- qwen2_lora_multimodal/

**√âtape 4 ‚Äî Inf√©rence multimodale sur de nouvelles images**

Lancer :
```
XVision-inference.ipynb
```

---

##üë§ Auteurs

Ce projet a √©t√© d√©velopp√© par Djebril Laouedj et Redha Ibbou,

√©tudiants en derni√®re ann√©e en Big Data & Intelligence Artificielle √† l'ECE Paris.
